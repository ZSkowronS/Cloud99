{"name":"Cloud99","tagline":"Framework for Openstack High Availability Testing","body":"![](https://github.com/cisco-oss-eng/Cloud99/blob/master/cloud.png?raw=true)\r\n## Cloud99 (Framework for Openstack HA Testing ##\r\n\r\nTesting an OpenStack cloud for High Availability(HA) is a critical aspect of certifying an OpenStack Cloud for production. But testing an OpenStack cloud to ensure that it meets the criteria for High Availability can become quite complex and involves a combination of several aspects\r\n\r\n - Generating an initial load on the cloud before testing starts\r\n - Health checks to make sure the cloud is ready for HA testing\r\n - Running control/plane data plane tests in parallel with service disruptions\r\n - Active monitoring of the cloud during the HA test run\r\n -  Quantification of failures and test results\r\n\r\nThis tool attempts to automate some of these workflows and makes it easier for the Cloud admin to trigger disruptions and asses \"how available\" the OpenStack cloud actually is. \r\n\r\nCloud99 has 3 important components built-in\r\n\r\n - Monitors\r\n - Disruptors\r\n - Runners\r\n\r\nAll 3 of the above are written using a plugin model so there can be several monitors, disruptors and runners based on your OpenStack deployment. For now we implement commonly used plugins for some of these. The sections below describe these in more detail. \r\n\r\n\r\n----------\r\nMonitors as the name suggests, monitor the cloud while the disruption event/tests are in progress. For now the following monitors are supported. \r\n\r\n - OpenStack API monitor (reports status of API services and agents)\r\n - Ansible Host monitor (uses ansible to login to all your openstack nodes and check service status)\r\n - Nagios monitor (Leverage Nagios agents if available in your openstack nodes, also always monitors application VMs on cloud)\r\n\r\nFor the Nagios monitor being used with Application VMs we prebuild a qcow2 images with nagios agent enabled and launch this on the cloud before testing starts. This flow will also be automated in the next release.\r\n\r\nDisruptors as the name suggests disrupts the Openstack services/Nodes. For now the following disruptors are supported\r\n\r\n - Node disruptor (reboots openstack nodes like compute and controllers)\r\n - Process disruptor (disrupts services on different nodes)\r\n - Container disruptor (supports stopping docker containers, more for container based openstack deployments)\r\n\r\nRunners are the critical part which actually runs scale/functionality tests in parallel with disruptions. This can be any script/framework that runs OpenStack tests. The only requirement is the framework should continue on failure as disruptions can cause failures. For now we support the following runner\r\n\r\n - Rally runner (provide a pre-installer rally framework and pointer to scenario file)\r\n\r\nThe framework spawns separate threads for each runner, monitor and disruptors and performs all these in parallel. So for example you can perform a test which Boots  a VM, stop the nova scheduler and monitors the cloud. All these actions happen in parallel.  \r\n\r\nNow lets talk about how to use the tool and commands involved\r\n\r\n----------\r\n**Getting Started**\r\n\r\n    git clone https://github.com/cisco-oss-eng/Cloud99.git\r\n    pip install -r requirements.txt\r\n    sudo ./install.sh\r\n    python ha_engine/ha_main.py -f configs/executor.yaml\r\n   \r\nBefore you run the tool you need to provide some information to the tool about your openstack cloud and also what kind of disruptions you would like to have. \r\n\r\nThe configs directory has information on configuration files that you need to modify to use the tool. \r\n\r\nSo let us look at what changes you need to make in the configuration files. In disruptors.yaml you specify the roles and names of your OpenStack processes and also if your controllers are running in seperate nodes.\r\n\r\nIn monitors.yaml under ansiblemonitor specify the Mysql/mariadb user and password. Also under healthapi provide a pointer to your openrc file and password or source your openrc before running the script.\r\n\r\nUnder openstack_config.yaml specify your openstack nodes with the roles you specified in disruptors.yaml. This would include the list of your controller and compute nodes.\r\n\r\nIn runners.yaml specify pointer to your rally installation and also a pointer to rally scenario file. For now we support rally as runner but if you need to add your own you need to add code to runners/plugin directory.\r\n\r\nNow finally the executor.yaml brings everything together where you can specify the kind of disruption and also in start specify what services to monitor. For now have \r\nstart: [openstack_api, ansible]\r\nYou can also specify here what kind of disruption you need. Look at the example files checked into configs directory to get an idea\r\nFinally run the command \r\npython ha_engine/ha_main.py -f configs/executor.yaml to run the tool\r\n\r\nIt will spawn xterms for monitors, disruptors and runners and you will see everything in action. Finally on the main window you see summary results\r\n\r\n**Caveats**\r\n\r\n 1. As specified before the tool is in beta phase so we expect to see a few issues but we help with support requests to our email alias \r\n 2. For now the rally runner needs a patch to rally summary report so please rally/cmd/commands/task.py with caveats/task.py and redo rally install. This fix will me merged into Rally and than you dont need this\r\n 2. For now the tool needs xterm to launch all the windows for different disruptors, ,monitors etc. This will be removed in future releases\r\n 3. The config files will be consolidated in future releases and you would not need to manipulate so many files\r\n 4. The nagios portion assumes you have a nagios server pre-installed somewhere. We will provide instructions for these in future releases\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}